{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What job are you thinking? Data Scientist\n",
      "As a Data Scientist, do you have any specific skills? pandas\n",
      "How much are you trying to make?(x 1000) 80\n",
      "Where do you want to work? Boulder\n",
      "How far are you willig to commute? 50\n",
      "Looking for something specific in this job? \n",
      "Looking to exempt specific words? \n",
      "Any speicific companies you're interested in? \n"
     ]
    }
   ],
   "source": [
    "#Indeed block\n",
    "key_word = input(\"What job are you thinking?\")\n",
    "key_phrase = input(f'As a {key_word}, do you have any specific skills?')\n",
    "salary_in_thousand = int(input(\"How much are you trying to make?(Input is x $1000)\"))\n",
    "city = input(\"Where do you want to work?\")\n",
    "radius = int(input(\"How far are you willing to commute in miles?\"))\n",
    "specific_word = input(\"Looking for something specific in this job?\")\n",
    "exempt_word = input(\"Looking to exempt specific words?\")\n",
    "specific_companies = input(\"Any speicific companies you're interested in?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = 'https://www.indeed.com/jobs?as_and=financial%20analyst&as_phr=excel&as_any&as_not&as_ttl&as_cmp&jt=all&st&salary=%24502C000%2B&radius=25&l=Atlanta&fromage=any&limit=10&sort&psf=advsrch&from=advancedsearch&vjk=cf17241bbbc07f8a&advn=9789631977364005'\n",
    "#url = (f'https://www.indeed.com/jobs?as_and={key_word}&as_phr={key_phrase}&as_any={specific_word}&as_not={exempt_word}&as_ttl={specific_word}&as_cmp={specific_companies}&jt=all&st=&salary=%24{salary_in_thousand}2C000%2B&radius={radius}&l={city}&fromage=any&limit=10&sort=&psf=advsrch&from=advancedsearch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve page with the requests module\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the results, then determine element that contains sought info\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for div in soup.find_all(name=”div”, attrs={“class”:”row”}):\n",
    "for a in div.find_all(name=”a”, attrs={“data-tn-element”:”jobTitle”}):\n",
    "      jobs.append(a[“title”])\n",
    "        return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results are returned as an iterable list\n",
    "job_tag = soup.find_all(name='a',attrs={\"data-tn-element\" : \"jobTitle\"})\n",
    "company_tag = soup.find_all(attrs={\"data-tn-element\" : \"companyName\"})\n",
    "# input_tag = soup.find_all(attrs={\"title\" : \"x\"})\n",
    "date_results = soup.find_all('span', class_=\"date\")\n",
    "job_title_results = soup.find_all('div', class_=\"jobtitle_turnstileLink_visited\")\n",
    "rating_results = soup.find_all('span', class_=\"ratingsContent\")\n",
    "# specific_loc = soup.find_all('span', class_=\"data-rc-loc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = []\n",
    "for div in soup:\n",
    "    soup.find_all(name=\"div\",attrs={\"class\":\"row\"})\n",
    "for a in div:\n",
    "    soup.find_all(name=\"a\",attrs={\"data-tn-element\":'jobTitle'})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratings results need to be displayed as single digit float\n",
    "\n",
    "Job title needs to be properly scraped\n",
    "\n",
    "Scrape more specific location\n",
    "\n",
    "Scrape the employer informatoin\n",
    "\n",
    "see if we can export to a DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through returned results\n",
    "for result in results:\n",
    "    # Error handling\n",
    "    try:\n",
    "        # Identify and return title of listing\n",
    "        rating = soup.find('span', class_=\"ratingsContent\").text\n",
    "        date = soup.find('span', class_=\"date\").text\n",
    "        title = soup.find('h2', class_=\"title\").text\n",
    "        employer = soup.find()\n",
    "        # Identify and return price of listing\n",
    "#         price = result.a.span.text\n",
    "        # Identify and return link to listing\n",
    "#         link = result.a['href']\n",
    "\n",
    "        # Print results only if title, price, and link are available\n",
    "        if (rating and date and title):\n",
    "            print('-------------')\n",
    "            print(title)\n",
    "            print(rating)\n",
    "            print(date)\n",
    "    except AttributeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (f'https://www.indeed.com/jobs?as_and={key_word}&as_phr={key_phrase}&as_any={specific_word}&as_not={exempt_word}&as_ttl={specific_word}&as_cmp={specific_companies}&jt=all&st=&salary=%24{salary_in_thousand}2C000%2B&radius={radius}&l={city}&fromage=any&limit=10&sort=&psf=advsrch&from=advancedsearch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
